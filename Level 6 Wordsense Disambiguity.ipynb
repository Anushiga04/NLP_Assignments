{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Word Sense Disambiguity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Given the following sentences:\n",
    "\n",
    "    The agent will book the to the show for the entire family.\n",
    "    But you can generally book tickets online.\n",
    "    When you book tickets online they provide you with a book of stamps\n",
    "    \n",
    "If you could see the above sentences the word book is used in different context. In first two sentences the word book(verb) refers to the meaning 'reserve' while in the second portion of the third sentence book(noun) refers to a physical entity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part - 1\n",
    "\n",
    "    Use the Lesk Module to find the similar words of the word *book* using the above sentences. Record your observations.\n",
    "    \n",
    "## Part - 2\n",
    "\n",
    "Tag sentences using Brill Tagger.\n",
    "\n",
    "### Brill Tagger\n",
    "\n",
    "The BrillTagger class is a **transformation-based tagger**. The BrillTagger class uses a series\n",
    "of rules to correct the results of an initial tagger. These rules are scored based on how many\n",
    "errors they correct minus the number of new errors they produce.\n",
    "\n",
    "The idea is simple Brill Tagger tries to correct the mistake made by the inital tagger. Brill tagger inputs an initial tagger and the templates which autmatically tells to create new rules based on the Training Set.\n",
    "\n",
    "**Recommended Steps:**\n",
    "\n",
    "1. Initially tag the sentence using POS Tagger. Then observe the POS tags for the word book in different context\n",
    "2. Then create a tagged_sentence using the POS Tagger correcting it with the mistakes it made.\n",
    "3. Now create a Brill Tagger using an initial tagger (POS) and pass templates(rules) to it.\n",
    "4. Train the Brill Tagger using the Tagged Sentence\n",
    "5. Test the Brill Tagger on the following sentences:\n",
    "       > \"I bought this book from Kerala\"\n",
    "       > \"He will book tickets to Kerala\"\n",
    "       \n",
    "## Part - 3\n",
    "\n",
    "    Perform Part-1 again but passing the POS tags produced by the Brill Tagger.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.wsd import lesk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import nltk.data\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.util import ngrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# PART - 1  ---- LESK MODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'The agent will book the to the show for the entire family.But you can generally book tickets online.When you book tickets online they provide you with a book of stamp.'\n",
    "type(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ambiguous = 'book'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('script.n.01')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesk(sent, ambiguous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a written version of a play or other dramatic composition; used in preparing for a performance'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesk(sent, ambiguous).definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# PART - 2 ----BRILL TAGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "txt_1 = 'The agent will book the to the show for the entire family.'\n",
    "txt_2 = 'But you can generally book tickets online.'\n",
    "txt_3 = 'When you book tickets online they provide you with a book of stamp.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_1 = word_tokenize(txt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_2 = word_tokenize(txt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_3 = word_tokenize(txt_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('book', 'NN')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_1 = nltk.pos_tag(word_1)[3]\n",
    "tag_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('book', 'NN')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_2 = nltk.pos_tag(word_2)[4]\n",
    "tag_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('When', 'WRB'),\n",
       " ('you', 'PRP'),\n",
       " ('book', 'NN'),\n",
       " ('tickets', 'NNS'),\n",
       " ('online', 'VBP'),\n",
       " ('they', 'PRP'),\n",
       " ('provide', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('with', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('book', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('stamp', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_3 = nltk.pos_tag(word_3)\n",
    "tag_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('agent', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('book', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('show', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('entire', 'JJ'),\n",
       " ('family.But', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('generally', 'RB'),\n",
       " ('book', 'NN'),\n",
       " ('tickets', 'NNS'),\n",
       " ('online.When', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('book', 'NN'),\n",
       " ('tickets', 'NNS'),\n",
       " ('online', 'VBP'),\n",
       " ('they', 'PRP'),\n",
       " ('provide', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('with', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('book', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('stamp', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sent_tokenize(sent)\n",
    "for word in sentences:\n",
    "    tagged_sentences = nltk.pos_tag(word_tokenize(word))\n",
    "tagged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DefaultTagger: tag=[('The', 'DT'), ('agent', 'NN'), ('will', 'MD'), ('book', 'NN'), ('the', 'DT'), ('to', 'TO'), ('the', 'DT'), ('show', 'NN'), ('for', 'IN'), ('the', 'DT'), ('entire', 'JJ'), ('family.But', 'NN'), ('you', 'PRP'), ('can', 'MD'), ('generally', 'RB'), ('book', 'NN'), ('tickets', 'NNS'), ('online.When', 'VBP'), ('you', 'PRP'), ('book', 'NN'), ('tickets', 'NNS'), ('online', 'VBP'), ('they', 'PRP'), ('provide', 'VBP'), ('you', 'PRP'), ('with', 'IN'), ('a', 'DT'), ('book', 'NN'), ('of', 'IN'), ('stamp', 'NN'), ('.', '.')]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaut_tagger = nltk.DefaultTagger(tagged_sentences)\n",
    "defaut_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('agent', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('book', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('show', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('entire', 'JJ'),\n",
       " ('family.But', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('generally', 'RB'),\n",
       " ('book', 'VB'),\n",
       " ('tickets', 'NNS'),\n",
       " ('online.When', '-NONE-'),\n",
       " ('you', 'PRP'),\n",
       " ('book', 'VB'),\n",
       " ('tickets', 'NNS'),\n",
       " ('online', 'NN'),\n",
       " ('they', 'PRP'),\n",
       " ('provide', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('with', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('book', 'VB'),\n",
       " ('of', 'IN'),\n",
       " ('stamp', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_path = '/home/anushya/nltk_data/taggers/maxent_treebank_pos_tagger/english.pickle'\n",
    "model = {'book': 'VB'}\n",
    "tagger = nltk.tag.UnigramTagger(model=model, backoff=nltk.data.load(tagger_path))\n",
    "sentences = sent_tokenize(sent)\n",
    "for word in sentences:\n",
    "    tagged_sentences = tagger.tag(word_tokenize(word))\n",
    "tagged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag.brill import *\n",
    "import nltk.tag.brill_trainer as bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Template(Word([0]),Word([1]),Word([2])),\n",
       " Template(Word([-1]),Word([0]),Word([1])),\n",
       " Template(Word([0]),Word([-1])),\n",
       " Template(Word([0]),Word([1])),\n",
       " Template(Word([0]),Word([2])),\n",
       " Template(Word([0]),Word([-2])),\n",
       " Template(Word([1, 2])),\n",
       " Template(Word([-2, -1])),\n",
       " Template(Word([1, 2, 3])),\n",
       " Template(Word([-3, -2, -1])),\n",
       " Template(Word([0]),Pos([2])),\n",
       " Template(Word([0]),Pos([-2])),\n",
       " Template(Word([0]),Pos([1])),\n",
       " Template(Word([0]),Pos([-1])),\n",
       " Template(Word([0])),\n",
       " Template(Word([-2])),\n",
       " Template(Word([2])),\n",
       " Template(Word([1])),\n",
       " Template(Word([-1])),\n",
       " Template(Pos([-1]),Pos([1])),\n",
       " Template(Pos([1]),Pos([2])),\n",
       " Template(Pos([-1]),Pos([-2])),\n",
       " Template(Pos([1])),\n",
       " Template(Pos([-1])),\n",
       " Template(Pos([-2])),\n",
       " Template(Pos([2])),\n",
       " Template(Pos([1, 2, 3])),\n",
       " Template(Pos([1, 2])),\n",
       " Template(Pos([-3, -2, -1])),\n",
       " Template(Pos([-2, -1])),\n",
       " Template(Pos([1]),Word([0]),Word([1])),\n",
       " Template(Pos([1]),Word([0]),Word([-1])),\n",
       " Template(Pos([-1]),Word([-1]),Word([0])),\n",
       " Template(Pos([-1]),Word([0]),Word([1])),\n",
       " Template(Pos([-2]),Pos([-1])),\n",
       " Template(Pos([1]),Pos([2])),\n",
       " Template(Pos([1]),Pos([2]),Word([1]))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Template._cleartemplates()\n",
    "templates = fntbl37()\n",
    "tagger = nltk.tag.brill_trainer.BrillTaggerTrainer(nltk.data.load('taggers/maxent_treebank_pos_tagger/PY3/english.pickle'),templates)\n",
    "trained_tagger = tagger.train([tagged_sentences])\n",
    "templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('bought', 'VBD'),\n",
       " ('this', 'DT'),\n",
       " ('book', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('Kerala.He', 'NNP'),\n",
       " ('will', 'MD'),\n",
       " ('book', 'VB'),\n",
       " ('tickets', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('Kerala', 'NNP')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_txt = 'I bought this book from Kerala.He will book tickets to Kerala'\n",
    "sentences_1 = sent_tokenize(test_txt)\n",
    "for word in sentences_1:\n",
    "    tagged_sentences_1 = trained_tagger.tag(word_tokenize(test_txt))\n",
    "tagged_sentences_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# PART - 3 ---- Implementing brill tagger in place of pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('agent', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('book', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('show', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('entire', 'JJ'),\n",
       " ('family.But', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('generally', 'RB'),\n",
       " ('book', 'VB'),\n",
       " ('tickets', 'NNS'),\n",
       " ('online.When', '-NONE-'),\n",
       " ('you', 'PRP'),\n",
       " ('book', 'VBP'),\n",
       " ('tickets', 'NNS'),\n",
       " ('online', 'VBP'),\n",
       " ('they', 'PRP'),\n",
       " ('provide', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('with', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('book', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('stamp', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_2 = sent_tokenize(sent)\n",
    "for word in sentences_2:\n",
    "    tagged_sentences_2 = trained_tagger.tag(word_tokenize(sent))\n",
    "tagged_sentences_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WRB',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'NNS',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_1 = trained_tagger.tag(word_3)\n",
    "tag1 = []\n",
    "for word,tag in tag_1:\n",
    "    tag1.append(tag)\n",
    "tag1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('script.n.01')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesk(txt_3,ambiguous_word='book',pos ='n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('book.v.04')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesk(txt_2,ambiguous_word='book',pos ='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('book.v.04')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesk(txt_1,ambiguous_word='book',pos ='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object ngrams at 0x7f817c4a9ba0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams=ngrams(word_1,2)\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
